{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "appreciated-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 2] elementwise multiplication\n",
      "[3 2 3] elementwise addition\n",
      "Error:[0.00053374] Prediction:-0.0026256193329783125\n"
     ]
    }
   ],
   "source": [
    "# You can train neural networks to convert a given dataset of \"what you know\" to a dataset of \"what you want to know\"\n",
    "# Basically, you can train the network to interpret observations.\n",
    "# First, convert the observation dataset into matrices so the information is interpretable for the network.\n",
    "    # Convention: use one row for one observation (each set of on/off lights on a 3-light streetlight) \n",
    "    # and one column per observed item (whether each light in the set is on or off). \n",
    "    # Ideally, you want a \"lossless representation\" - the data and the matrix can be perfectly converted between each other.\n",
    "    \n",
    "import numpy as np\n",
    "weights = np.array([0.5, 0.48, -0.7])\n",
    "alpha = 0.1\n",
    "\n",
    "# input data pattern\n",
    "# 0 = light is off, 1 = light is on in a 3-light horizontal stoplight at a crosswalk\n",
    "streetlights = np.array([[1, 0, 1],\n",
    "                       [0, 1, 1],\n",
    "                       [0, 0, 1],\n",
    "                       [1, 1, 1],\n",
    "                       [0, 1, 1],\n",
    "                       [1, 0, 1]])\n",
    "# output data pattern \n",
    "# 0 = stop, 1 = walk\n",
    "walk_vs_stop = np.array([[0],\n",
    "                        [1],\n",
    "                        [0],\n",
    "                        [1],\n",
    "                        [1],\n",
    "                        [0]])\n",
    "\n",
    "# First, we can turn streetlights into walk_vs_stop with a neural network, as before.\n",
    "# Uses nice numpy arrays to do elementwise addition/multiplication easily, otherwise is same as previous neural networks.\n",
    "print(streetlights[0] * [2, 2, 2], \"elementwise multiplication\")\n",
    "print(streetlights[0] + [2, 2, 2], \"elementwise addition\")\n",
    "\n",
    "for iteration in range(40):\n",
    "    error_for_all_lights = 0\n",
    "    for row in range(len(walk_vs_stop)):\n",
    "        input = streetlights[row]\n",
    "        goal_prediction = walk_vs_stop[row]\n",
    "        \n",
    "        # dot product = weighted sum: input * weights and addition of all items in vector to return a single number\n",
    "        # The weighted sum of inputs finds perfect correlation between input and output by weighting decorrelated inputs to 0.\n",
    "        # Basically, if the light is off (marked 0), it will have no effect on the outcome because 0 * anything = 0.\n",
    "        # So anytime a light has an effect, it will not be 0 and it will be accounted for as a value that affects the outcome.\n",
    "        prediction = input.dot(weights) \n",
    "        error = (goal_prediction - prediction) ** 2\n",
    "        error_for_all_lights += error\n",
    "        \n",
    "        delta = prediction - goal_prediction \n",
    "        weights = weights - (alpha * (input * delta))\n",
    "\n",
    "print(\"Error:\" + str(error_for_all_lights) + \" Prediction:\" + str(prediction))\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "# The network goes through the training examples one at a time and iterates over it several times. This lets it update the \n",
    "# weights for all examples until the network is capable of predicting the correct answer when faced with all training examples.\n",
    "# This was essentially what we did in ch5 to train the handwriting neural network. We did not have a separate error for the\n",
    "# entire dataset, however. We just updated the error for each digit 0-9 and used that error for all instances of that digit\n",
    "# in the dataset. This doesn't seem to make a difference for the network's learning because we don't actually use the error \n",
    "# value to learn. We use delta, which is just kind of related.\n",
    "\n",
    "# (Average/Full) Gradient Descent\n",
    "# The network goes through the entire set of training examples and calculates the average weight_delta for the whole dataset.\n",
    "# Then, the network changes the weights one time. The network does not change the weights for every data point.\n",
    "\n",
    "# Batch Gradient Descent\n",
    "# Updates the weights after n data points. Batch size is chosen by the user and is typically between 8 and 256. This will be\n",
    "# discussed more later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-aircraft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfitting\n",
    "# There is an edge case where the network will predict the right answer but not actually learn. For example, what if the left\n",
    "# and right weights were 0.5 and -0.5 respectively and our data point was [1, 0, 1]? Then the weighted sum (prediction) would \n",
    "# be 0. The prediction was correct (stop), but the network did not learn anything.\n",
    "\n",
    "# Error is shared among all weights. If some weight configuration accidentally creates perfect correlation between the \n",
    "# prediction and the expected output (error = 0), then weights will not be updated properly and the network will not learn from\n",
    "# this data point.\n",
    "\n",
    "# Overfitting is really only a problem if you only train on data points that the network cannot learn off of. The other data\n",
    "# points should bump the weights out of this configuration and you can continue learning as long as you see other data points.\n",
    "\n",
    "# Networks should be exposed to plenty of data in order to make sure they learn the rule. They need to learn to generalize \n",
    "# instead of memorizing some specific examples and reacting accordingly.\n",
    "\n",
    "# Conflicting Pressure\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
